{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Dependencies"
      ],
      "metadata": {
        "id": "Yv53gD6Jdfg9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "6TDhPemjO1_2"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrpa meta description by URL"
      ],
      "metadata": {
        "id": "P4EmZY-1dklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def scrape_website(url):\n",
        "\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for non-200 status codes\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        data = {\n",
        "            'url': url,\n",
        "\n",
        "            'meta_description': None,\n",
        "\n",
        "        }\n",
        "\n",
        "\n",
        "        meta_description = soup.find('meta', attrs={'name': 'description'})\n",
        "        if meta_description:\n",
        "            data['meta_description'] = meta_description['content']\n",
        "            text = data[\"meta_description\"]\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error scraping website: {e}\")\n",
        "        return text\n",
        "\n",
        "# Example usage\n",
        "# url = 'https://www.allheartweb.com'\n",
        "url = input('Input url : ')\n",
        "text = scrape_website(url)\n",
        "\n",
        "if text:\n",
        "    print(text)\n",
        "else:\n",
        "    print(\"Scraping failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEJvlQiwWKHk",
        "outputId": "4b31c218-b209-4ba3-abbd-0a3e0331d1ad"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input url : https://www.allheartweb.com\n",
            "Redefining Domain Intelligence with AllHeartWeb.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import training data"
      ],
      "metadata": {
        "id": "nZiy9rb1dpm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"website_classification.csv\")"
      ],
      "metadata": {
        "id": "3NybnXdYO-Hm"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8UxzMxKPAUU",
        "outputId": "da032c9d-edff-46ae-8d93-3689c2c06fb9"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1408 entries, 0 to 1407\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   Unnamed: 0            1408 non-null   int64 \n",
            " 1   website_url           1408 non-null   object\n",
            " 2   cleaned_website_text  1408 non-null   object\n",
            " 3   Category              1408 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 44.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove unnecessary columns from Code"
      ],
      "metadata": {
        "id": "cRXrYY_Wd0JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop([\"Unnamed: 0\",\"website_url\"],axis=1)"
      ],
      "metadata": {
        "id": "y95lsTJCPGVk"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.cleaned_website_text.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLPu1EaVPGoi",
        "outputId": "5e0aac09-bb82-4a33-b28a-34c27e592dfb"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    official site good hotel accommodation big sav...\n",
              "1    expedia hotel book sites like use vacation wor...\n",
              "2    tripadvisor hotel book sites like previously d...\n",
              "3    cheap flights search compare flights momondo f...\n",
              "4    bot create free account create free account si...\n",
              "Name: cleaned_website_text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove duplicates"
      ],
      "metadata": {
        "id": "BuWDysQOd9Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop_duplicates()"
      ],
      "metadata": {
        "id": "p23pg0oJPRKO"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seggregate columns"
      ],
      "metadata": {
        "id": "oc8VC_0Cd_ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature=data['cleaned_website_text']\n",
        "target=data['Category']\n",
        "feature=pd.DataFrame(feature)"
      ],
      "metadata": {
        "id": "hpQ3hug1PTRa"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoded target column"
      ],
      "metadata": {
        "id": "H7uk6Bz4eF8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder=LabelEncoder()\n",
        "target=label_encoder.fit_transform(target)"
      ],
      "metadata": {
        "id": "CxJqfcqnPUuh"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning"
      ],
      "metadata": {
        "id": "FD95PIf2eJXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Cleaning the feature column\n",
        "def cleaning_processing(sentance):\n",
        "    stop_words=set(stopwords.words('english'))\n",
        "    sentance=word_tokenize(sentance)  # Split the sentence in two words\n",
        "    sen=[]\n",
        "    for i in sentance:\n",
        "        sentance=i.lower()   # convert into lower_case\n",
        "        sentance=re.sub(r\"[^a-zA-Z]\",\"\",sentance) # Remove special_charater\n",
        "        if sentance not in stop_words:\n",
        "            if sentance != '': # Remove empty string\n",
        "                sen.append(sentance)\n",
        "    filtered_sentence = \" \".join(sen)  # Converting a list of words into a string\n",
        "    return filtered_sentence"
      ],
      "metadata": {
        "id": "hRbm6CNNPWnf"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLZ_4jhzPYee",
        "outputId": "b25b2b0a-bd2a-445e-8e33-106ab41213d6"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature[\"cleaned_website_text\"]=feature[\"cleaned_website_text\"].apply(cleaning_processing)"
      ],
      "metadata": {
        "id": "Rea2OBeBPgFs"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text = text[\"meta_description\"]\n",
        "# text = \"tripadvisor hotel book sites like previously deal predominantly restaurant bar review recent year tripadvisor begin offer hotel reservation fine result unlike tripadvisor alternative sites tripadvisor blog travelsites hotel book sites tripadvisor home visit site vote previously deal predominantly restaurant bar review recent year tripadvisor begin offer hotel reservation fine result unlike tripadvisor compare cost number book website include give option view deal order find good price like tripadvisor find stay accommodation detail bit thin website review system useful choose spend hard earn cash select review depend language traveller type time year give good idea like stay hotel precisely plan tripadvisor give option find key word review example good location type location traveller say comment website include contact detail hotel link hotel specific website give user feeling restrict book tripadvisor want photo place divide professional photo traveller photo add transparency make booking know happy tripadvisor feature tell people look property aggressive pop up partner company believe make user feel ease make reservation website time feel convoluted review post trust tripadvisor great tool find book accommodation david jones professional travel writer travel enthusiast travel world twice share firsthand knowledge relate travel spending time abroad pro allow user compare result website help find good deal user review refine filter order find specifically look user professional photo user photo good sense hotel like contact info hotel website include con little information type accommodation compare book website website feel convoluted confusing time ranks hotel user view user review trust expedia agoda priceline orbitz travelocity hotwire hotelscombined momondo hotels onetravel hotels hotel booking sites click travel list travel sites check big date travel list good travel site click good travel sites blog world good travel si\""
      ],
      "metadata": {
        "id": "jRZ5B0RHSZ_i"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Scrapped Text"
      ],
      "metadata": {
        "id": "gl1Jm0MdeVdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = cleaning_processing(text)\n",
        "list1 = [text]\n",
        "con_vector=TfidfVectorizer(max_features = 140)\n",
        "# text = list1\n",
        "text=con_vector.fit_transform(list1)\n"
      ],
      "metadata": {
        "id": "NEAWb-cjQj4Q"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxfeatures = text.shape[1]"
      ],
      "metadata": {
        "id": "YTITSrcjYDHO"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "maxfeatures is the features extracted from the scrapped text\n",
        "we require the no. of training features to be the same as the no. of input features"
      ],
      "metadata": {
        "id": "j_FMyDngeaqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "con_vector=TfidfVectorizer(max_features = maxfeatures)\n",
        "feature=con_vector.fit_transform(feature[\"cleaned_website_text\"])"
      ],
      "metadata": {
        "id": "xVwjQATDPiHX"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test train split"
      ],
      "metadata": {
        "id": "9TzsJoxDfeyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MqzRX_3HSR54"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", x_train.shape)\n",
        "print(\"X_test shape:\", x_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXyGMNg3S8Ih",
        "outputId": "38c1c8dd-3e21-4acf-8f0f-c62b6398f330"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1100, 4)\n",
            "X_test shape: (275, 4)\n",
            "y_train shape: (1100,)\n",
            "y_test shape: (275,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2f4IyAhzS9--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model , KNN in this case"
      ],
      "metadata": {
        "id": "3eFeSXx8fhhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1=KNeighborsClassifier()\n",
        "# x_train = x_train[0:30]\n",
        "classifier1.fit(x_train,y_train)\n",
        "predict1=classifier1.predict(x_test)\n",
        "accuracy1 = accuracy_score(y_test, predict1)\n",
        "print(\"KNeighborsClassifier accuracy score: \",accuracy1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIDkX91VS_vo",
        "outputId": "57205341-6bc5-4bd1-c25d-c8afa3f5fadf"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsClassifier accuracy score:  0.11272727272727273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining categories"
      ],
      "metadata": {
        "id": "J-isqlLPfkrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_labels = data['Category'].values  # Get the category column as a NumPy array\n",
        "category_labels_1d = set(category_labels)\n",
        "category_labels_1d = category_labels.flatten()\n",
        "\n",
        "# category_labels_1d"
      ],
      "metadata": {
        "id": "CId1p2EYTBVg"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "processing input"
      ],
      "metadata": {
        "id": "cnpOtWc-fqEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = classifier1\n",
        "\n",
        "new_website_text = text\n",
        "print(new_website_text.shape)\n",
        "# Predict the category using the loaded model\n",
        "predicted_category = model.predict(new_website_text)[0]\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(category_labels_1d)\n",
        "\n",
        "category_names = label_encoder.inverse_transform([predicted_category])\n",
        "\n",
        "print(\"Predicted category:\", category_names[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfIppwSBTETr",
        "outputId": "49ca5505-a17c-43e3-ef2a-1d7744146860"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4)\n",
            "Predicted category: Games\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C9SKhndFTgJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}